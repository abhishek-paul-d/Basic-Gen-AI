{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0cf8dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e293ef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000016DCFDCEB90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000016DCFDCDA50>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "554be422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Abhishek!\\n\\nIt's great to meet you. BITS Pilani, Hyderabad Campus is a fantastic institution.  \\n\\nWhat are you studying there? Are you enjoying your time at BITS?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 27, 'total_tokens': 69, 'completion_time': 0.076363636, 'prompt_time': 0.00141288, 'queue_time': 0.248440908, 'total_time': 0.077776516}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--49a85f8d-8770-49af-8278-31c33b1f277a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 42, 'total_tokens': 69})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hey My Name is Abhishek and I am a student at BITS Pilani,Hyderabad Campus.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49da42f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Abhishek and you study at BITS Pilani, Hyderabad Campus!  \\n\\nIs there anything else you'd like to talk about? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 93, 'total_tokens': 129, 'completion_time': 0.065454545, 'prompt_time': 0.002576969, 'queue_time': 0.249445402, 'total_time': 0.068031514}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--993f0ac4-7a17-40d9-abb8-6e54d1365646-0', usage_metadata={'input_tokens': 93, 'output_tokens': 36, 'total_tokens': 129})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To make sure the model can respond to follow-up questions\n",
    "from langchain_core.messages import AIMessage\n",
    "model.invoke( \n",
    "    [ \n",
    "        HumanMessage(content=\"Hey My Name is Abhishek and I am a student at BITS Pilani,Hyderabad Campus.\"),\n",
    "        AIMessage(content=\"Hey Abhishek,\\n\\nNice to meet you! It's great to know you're a student at BITS Pilani, Hyderabad Campus. \\n\\nWhat are you studying there? Are you enjoying your time at BITS Pilani?\"),\n",
    "        HumanMessage(content=\"Hey Whats my name and where do I study?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90814070",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "881396f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e598a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My Name is Abhishek and I am a student at BITS Pilani,Hyderabad Campus.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbb070f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey Abhishek!\\n\\nThat's cool! BITS Pilani, Hyderabad Campus is a great place. \\n\\nWhat are you studying there? \\n\\nAre you enjoying your time at BITS Pilani?\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1929e28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Abhishek and you study at BITS Pilani, Hyderabad Campus!  \\n\\nIs there anything else you'd like to tell me? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 88, 'total_tokens': 124, 'completion_time': 0.065454545, 'prompt_time': 0.00251793, 'queue_time': 0.24719418, 'total_time': 0.067972475}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--b63d4826-c503-4bc7-8cfa-f80b0a6925da-0', usage_metadata={'input_tokens': 88, 'output_tokens': 36, 'total_tokens': 124})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey Whats my name and where do I study?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c415a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and no access to personal information about you, including your name or where you study. If you'd like to tell me, I'm happy to know! üòä\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Change the config to a different session_id\n",
    "config1= {\"configurable\":{\"session_id\": \"chat2\"}}\n",
    " \n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey Whats my name and where do I study?\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4f48061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Paul! Nice to meet you. üòä \\n\\nIs there anything I can help you with today?\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My Name is Paul\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b50d326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Paul!  üòä  I remember. \\n\\nAnything else I can help you with?\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b4d36",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f2084bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant, Answer all the questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e775d34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Abhishek, it's nice to meet you! \\n\\nHow can I help you today? üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 31, 'total_tokens': 57, 'completion_time': 0.047272727, 'prompt_time': 0.00149344, 'queue_time': 0.24726161, 'total_time': 0.048766167}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44cd5bba-a8d3-45aa-9b85-acdd2da5dc6a-0', usage_metadata={'input_tokens': 31, 'output_tokens': 26, 'total_tokens': 57})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My Name is Abhishek\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3d49d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96d672e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Abhishek! It's nice to meet you. üòä\\n\\nI'm ready to answer your questions. What can I help you with today?  \\n\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config= {\"configurable\":{\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi My Name is Abhishek\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46b830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD MORE COMPLEXITY TO THE PROMPT\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant, Answer all the questions to the best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63ded9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"‡∞Æ‡±Ä‡∞∞‡±Å Abhishek ‡∞Ö‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±Å ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞ï‡∞≤‡∞Ç ‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞∏‡∞π‡∞æ‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞æ‡∞ï‡±Å ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞§‡±á, ‡∞®‡∞æ ‡∞∂‡∞ï‡±ç‡∞§‡∞ø ‡∞Ö‡∞µ‡∞ß‡±Å‡∞≤‡∞≤‡±ã ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. üòä\\n\\n(Translation: Your name is Abhishek, I'm happy to know that. I'm ready to help you. Ask me anything, and I will answer to the best of my ability.) \\n\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My Name is Abhishek\")], \"language\": \"Telugu\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1f52941",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ab35535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∞®‡∞Æ‡∞∏‡±ç‡∞§‡±á Abhishek! üòä \\n\\n‡∞®‡∞æ‡∞ï‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡∞ï‡±Å ‡∞â‡∞§‡±ç‡∞§‡∞∞‡∞Ç ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Ç‡∞§‡±ã‡∞∑‡∞Ç. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞Ç ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞§‡±á, ‡∞®‡±á‡∞®‡±Å ‡∞®‡∞æ ‡∞∂‡∞ï‡±ç‡∞§‡∞ø ‡∞µ‡∞∞‡∞ï‡±Å ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. \\n\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config= {\"configurable\":{\"session_id\": \"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi My Name is Abhishek\")],\"language\": \"Telugu\"},\n",
    "    config=config\n",
    ") \n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2848e",
   "metadata": {},
   "source": [
    "### Managing the conversation history\n",
    "'trim_messages'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5071ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant, Answer all the questions to the best of your ability', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I am studying Mechanical Engineering and I am enjoying my time at BITS Pilani.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's great to hear! Mechanical Engineering is a fascinating field. \\n\\nWhat specific areas of Mechanical Engineering are you most interested in? Do you have any favorite projects or experiences at BITS Pilani so far?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I am interested in AI and I have worked on a few projects related to it. I also enjoy the campus life at BITS Pilani.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"AI is an exciting area to explore, especially in the context of Mechanical Engineering. \\n\\nIt's great that you're working on projects related to it. BITS Pilani has a vibrant campus life, and I'm sure you're making the most of it! \\n\\nIf you have any specific questions or topics you'd like to discuss, feel free to ask.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.utils import trim_messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=200,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model.get_num_tokens_from_messages,\n",
    "    include_system=True,\n",
    "    allow_partial=True,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant, Answer all the questions to the best of your ability\"),\n",
    "    HumanMessage(content=\"Hey My Name is Abhishek and I am a student at BITS Pilani,Hyderabad Campus.\"),\n",
    "    AIMessage(content=\"Hey Abhishek,\\n\\nNice to meet you! It's great to know you're a student at BITS Pilani, Hyderabad Campus. \\n\\nWhat are you studying there? Are you enjoying your time at BITS Pilani?\"),\n",
    "    HumanMessage(content=\"I am studying Mechanical Engineering and I am enjoying my time at BITS Pilani.\"),\n",
    "    AIMessage(content=\"That's great to hear! Mechanical Engineering is a fascinating field. \\n\\nWhat specific areas of Mechanical Engineering are you most interested in? Do you have any favorite projects or experiences at BITS Pilani so far?\"),\n",
    "    HumanMessage(content=\"I am interested in AI and I have worked on a few projects related to it. I also enjoy the campus life at BITS Pilani.\"),\n",
    "    AIMessage(content=\"AI is an exciting area to explore, especially in the context of Mechanical Engineering. \\n\\nIt's great that you're working on projects related to it. BITS Pilani has a vibrant campus life, and I'm sure you're making the most of it! \\n\\nIf you have any specific questions or topics you'd like to discuss, feel free to ask.\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41445a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are studying **Mechanical Engineering** at BITS Pilani.  \\n\\nYou mentioned it at the beginning of our conversation! üòä \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "    |prompt | model\n",
    ")\n",
    "\n",
    "response=chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What am I studying\")],\n",
    "    \"language\": \"English\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0d1083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets wrap this in the message history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04651103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said you are studying **Mechanical Engineering** at BITS Pilani.  \\n\\n\\nLet me know if you have any other questions about your studies or anything else! I'm here to help.\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What am I studying\")],\n",
    "    \"language\": \"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae3e35",
   "metadata": {},
   "source": [
    "### Vector Stores and Retreivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d19a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"dog_facts.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent animals, often known for their playful and curious nature.\",\n",
    "        metadata={\"source\": \"cat_facts.txt\"}                \n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Birds are fascinating creatures, often admired for their ability to fly and their diverse species.\",\n",
    "        metadata={\"source\": \"bird_facts.txt\"}       \n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Fish are aquatic animals, known for their gills and fins, and they come in various species.\",\n",
    "        metadata={\"source\": \"fish_facts.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Reptiles are cold-blooded animals, often characterized by their scaly skin and ability to live in diverse environments.\",\n",
    "        metadata={\"source\": \"reptile_facts.txt\"}\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "abec73af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'dog_facts.txt'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       " Document(metadata={'source': 'cat_facts.txt'}, page_content='Cats are independent animals, often known for their playful and curious nature.'),\n",
       " Document(metadata={'source': 'bird_facts.txt'}, page_content='Birds are fascinating creatures, often admired for their ability to fly and their diverse species.'),\n",
       " Document(metadata={'source': 'fish_facts.txt'}, page_content='Fish are aquatic animals, known for their gills and fins, and they come in various species.'),\n",
       " Document(metadata={'source': 'reptile_facts.txt'}, page_content='Reptiles are cold-blooded animals, often characterized by their scaly skin and ability to live in diverse environments.')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7ca6573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000016DCFD3CA30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000016DD0C94100>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72861a26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LRScheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[1;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:69\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     71\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderTrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderTrainingArguments\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderModelCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\trainer.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator, SequentialEvaluator\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerTrainer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datasets_available, is_training_available\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available():\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\sentence_transformers\\trainer.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollator\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WandbCallback\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TRAINING_ARGS_NAME\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvalLoopOutput\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerDataCollator\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\transformers\\trainer.py:73\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, load_sharded_checkpoint, unwrap_model\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[0;32m     71\u001b[0m     MODEL_MAPPING_NAMES,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adafactor, get_scheduler\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProcessorMixin\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     76\u001b[0m     is_torch_greater_or_equal_than_2_3,\n\u001b[0;32m     77\u001b[0m )\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\transformers\\optimization.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LambdaLR, ReduceLROnPlateau\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_pt_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseDummyOptimizer, LayerWiseDummyScheduler\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SchedulerType\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "File \u001b[1;32md:\\GenAI Projects\\venv\\lib\\site-packages\\transformers\\trainer_pt_utils.py:1372\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m   1369\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLayerWiseDummyScheduler\u001b[39;00m(\u001b[43mLRScheduler\u001b[49m):\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m    For Layer-wise optimizers such as GaLoRE optimizer, the optimization and scheduling step\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    are already done through the post gradient hooks. Therefore\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m    the trick is to create a dummy scheduler that can take arbitrary\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;124;03m    args and kwargs and return a no-op during training.\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LRScheduler' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0935b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VectorStores\n",
    "from langchain_chroma import Chroma\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
